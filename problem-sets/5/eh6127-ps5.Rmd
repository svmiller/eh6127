---
title: "Problem Set #5"
subtitle: "EH6105 - Quantitative Methods"
author: Steven V. Miller
output: pdf_document

fontfamily: cochineal
fontsize: 11pt
header-includes:
   - \linespread{1.05}
urlcolor: blue
---

This homework makes use of data available in `{stevedata}` and implies the use of `{tidyverse}` to answer the questions. It will also require some functions available in `{stevemisc}`, and `{lmtest}`. The final question in this lab script will be a "choose your adventure" for functionality, though I am electing to use the `{sandwich}` package.

```{r, message = F}
library(tidyverse)
library(stevedata)
library(stevemisc)
library(lmtest)
# library(sandwich); library(modelsummary)
```


# U.S. Foreign Aid and Human Rights in Assorted Years

This homework will refer to the `USFAHR` data set that is available in `{stevedata}`. These data offer students the opportunity to explore the relationship between human rights records and U.S. economic aid allocation at midway points of various U.S. presidential administrations. Per the letter of American law, U.S. economic assistance is determined in large measure by human rights practices of a recipient country. However, the tension between the law (with its underlying normative commitments) and the application of the law is a tension that borders on a farce for the largest aid granter in the world. As just one example, it has long been difficult to reconcile the John F. Kennedy that slashed economic assistance to the Park dictatorship for being embarrassing with the John F. Kennedy that oversaw a 260-fold increase in U.S. economic assistance to the Dominican Republic, arguably an even bigger pariah state at this time.[^rok]

[^rok]: From 1961 to 1962, the United States reduced economic grants to South Korea by 48% and offset the cuts with loans on less than generous terms. The Kennedy Administration understood South Korea's strategic importance but had (more than) reasonable doubts about the sincerity and the capability of the Park dictatorship. Park (1999) and Brazinsky (2005) are good background reads on the change in attitudes in American leadership to South Korea around this time. Taffett's chapter (chp. 16) in Selverstone's (2014) *A Companion to John F. Kennedy* offers some context into the difficulty for Kennedy in squaring rhetoric with reality in Latin America. Cuba, obviously, looms large in this conversation.

For added context, interest in this topic emerges in the mid-to-late 1980s as a result of several factors. First, data sets like the CIRI Human Rights Dataset and Freedom House emerge as reasonable estimates of human rights abuses that *aren't* provided by the U.S. Department of State.[^dd] Second, scholars at this time were able to leverage this new information and the slow proliferation of data to note that U.S. presidents like Jimmy Carter and Ronald Reagan could, prima facie, be wildly different in what they say about human rights but be arguably indistinguishable in the foreign policies they implement. Quantitative analyses from around this time were largely interested in comparing the two. See, for just two examples[^more]:

- Lebovic, James H. 1988. "National Interests and US Foreign Aid: The Carter and Reagan Years". *Journal of Peace Research* 24(2): 115-35.
- Poe, Steven C. 1992. "Human Rights and Economic Aid Allocation under Ronald Reagan and Jimmy Carter". *American Journal of Political Science* 36(1): 147-67.


[^dd]: Innes de Neufville (1986) provides a 10-year review of U.S. human rights reporting from its inception, and you can imagine how non-credible some of these reports were on sensitive places like Chile or Iran around this time.
[^more]: You should explore Google Scholar for even more. Type the following into Google Scholar: `us foreign aid carter reagan human rights`. There is a lot available to you to acclimate you on this topic.

You can find out more information about the data by visiting [this part of the package's website](http://svmiller.com/stevedata/reference/USFAHR.html), or with the following command.

```r
?USFAHR
```


Here's a little preview of these data.

```{r}
USFAHR
```

```{r, echo=F, eval=T}
USFAHR %>%
  filter(year %in% c(1979, 1983)) %>%
  filter(constoblig != 0) %>%
  filter(region %in% c("Latin America and Caribbean", "Sub-Saharan Africa",
                       "Middle East and North Africa", "Asia")) %>%
  mutate(gdppc = gdp/pop,
         milexpc = milex/(pop/1000)) %>%
  log_at(c("nomoblig", "constoblig")) -> Data

# 
# USFAHR %>%
#   filter(year %in% c(1979, 1983)) %>%
#   #filter(constoblig != 0) %>%
#   filter(region %in% c("Latin America and Caribbean", "Sub-Saharan Africa",
#                        "Middle East and North Africa", "Asia")) %>%
#   mutate(gdppc = gdp/pop,
#          milexpc = milex/(pop/1000)) -> A
# 
# A %>%
#   mutate(aid = ifelse(nomoblig == 0, 0, 1)) -> A
# 
# M0 <- glm(aid ~ clphy + fpsusa + fpsrus + mindistusa + usaimp + gdppc + milexpc + cinc,
#          data = subset(A, year == 1983),
#          family = binomial(link='probit'))

M1 <- lm(ln_constoblig ~ clphy + fpsusa + fpsrus + mindistusa + usaimp + gdppc + milexpc + cinc,
         data = subset(Data, year == 1979))
M2 <- lm(ln_constoblig ~ clphy + fpsusa + fpsrus + mindistusa + usaimp + gdppc + milexpc + cinc,
         data = subset(Data, year == 1983))

Data %>%
  log_at(c("milexpc","mindistusa", "usaimp"), plus_1 = TRUE) %>%
  mutate(ln_gdppc = log(gdppc)) -> Data


M3 <- lm(ln_constoblig ~ clphy + fpsusa + fpsrus + ln_mindistusa + ln_usaimp + ln_gdppc + ln_milexpc + cinc,
         data = subset(Data, year == 1979))



```

Answer these questions. A successful answer of these question must include the R code you used to help you answer the question. Each question is worth two points.

1. This is less of a question and more of a command. I need you to do the following for this exercise:

    a. Subset the data to just the years 1979 and 1983 so that we can compare a Jimmy Carter year with a Ronald Reagan year.
    b. Filter out any cases where the dollar amount of aid received is 0.[^select]
    c. Subset the data to just the regions of Latin America, Sub-Saharan Africa, the Middle East/North Africa, and Asia. Be mindful you have to be exact in how you identify these regions.
    d. Create two variables: 1) GDP per capita, and 2) military expenditures per capita. Be mindful the population variable is in units of 1 whereas the military expenditure variable is in thousands USD. Be smart here.
    e. Log-transform the variable communicating aid obligations in constant 2019 USD.
    f. Assign to an object called `Data`. Show me the code you used to do all this and communicate the dimensions (rows, columns) of these reduced data to prove to me you got it correct.
2. Run these two linear models and communicate the results to me in five-to-seven complete sentences. This particular analysis is largely patterned off the Lebovic (1988) article, which you can think of as an analysis of the effect of human rights considerations vis-a-vis other, more \**shudder*\* "realist" factors like power, proximity, and affinity (antipathy) to American (Soviet) policy positions.

    a. Regress the logged obligations variable you created above on the physical violence index, the foreign policy similarity with the United States, the foreign policy similarity with the Soviet Union, the minimum distance of the country to the United States, the value of how much the U.S. imports from the country, GDP per capita, military expenditures per capita, and the composite index of national capabilities.[^scale] Run this model *only* for the observations in 1979 (i.e. the Carter model).[^protip]
    b. Keep the exact same dependent variable and independent variables as above, but run this model *only* for the observations in 1983 (i.e. the Reagan model).
3. Do the following diagnostics. Show me the code you used as well.

    a. Use the `linloess_plot()` function, or `residualPlots()` from the `{car}` package, to identify potential non-linearity in the 1979 model. Tell me what you see. Of note: you could just as well do this for the 1983 model. Both will point to to some additional data issues or potential data transformations youâ€™ll want to consider.
    b. Assess whether the residuals are normally distributed for *both* models. You can take your pick here of the particular approach.
    c. Test for heteroskedasticity in both models and communicate the results of your assessment in 1-2 complete sentences.

4. Let's focus on the 1979 model for this exercise. The heteroskedasticity test is implying the test statistics are potentially suspect and the visual diagnostics you did are pointing to some culprits. Now, let's run two alternate models on the same basic data to explore how sensitive the results of the original model are. Identify what inferences you may want to report from the first model are sensitive to these design decisions. See Table 1 in this problem set for the fun I had with these data.

    a. Considering the information from your answer to the first part of the third question, employ additional data transformations (where appropriate) to the independent variables in the model. Explain what you're doing and why you're doing it. Be mindful that natural logarithms of 0 are undefined. A Breusch-Pagan test you run on a model with these assorted transformations you make should not have a *p*-value below .10.
    b. Run one other heteroskedasticity correction model, either through some kind of on-the-fly standard error correction or through a bootstrap.

[^select]: We are building in a strong assumption about the absence of potential selection effects here. For example, Gibler (2008, *Journal of Politics*) finds that human rights considerations matter only for the decision to award or withhold aid. Selecting on a decision to grant aid, human rights records have no effect and the dollar amount of aid is mostly a function of need.
[^protip]: Here's a regression modeling pro-tip in R. add `na.action = na.exclude` as an additional argument to the `lm()` command after the formula. This is going to be useful for when you have missing observations in the data that you want to ignore. It's not necessary, but it's useful.

[^scale]: This is a friendly reminder about scale in your model. Regression coefficients communicate the effect of one-unit changes on the estimated value of *y*. Sometimes the "one unit" is a min/max effect. Sometimes the "one unit" is one dollar (per capita). Be mindful about these issues, and be reasonable about what you expect a model to tell you.
<!-- [^scale]: Be mindful that the CINC variable is a proportion of the world's total capabilities in a given year. Thus, the technically correct interpretation of a regression coefficient in this context is the effect on aid allocation of a state going from completely powerless to having all the power in the world. However, any situation in which that is a true is one in which the U.S. would have no money to allocate to this hypothetical hegemon. Multiplying a proportion by 100 to return a percentage communicates a partial effect that is appropriately scaled and less of an eyesore. You could just as well take the coefficient in the model I'm asking you to estimate and divide it by 100 to communicate a one-unit percentage point effect. -->

\newpage

# Assorted Notes

- If it helps the student identify some of the references I cite, note that Brazinsky (2005) is in *Diplomatic History*, Gibler (2008) is in *Journal of Politics*, Innes de Neufville (1986) is in *Human Rights Quarterly*, and Park (1999) is in *Korean Studies*. Use Google Scholar and some basic context searching to identify the material to which I allude here.
- `{peacesciencer}` does a lot of heavy-lifting in creating these data. The codebook for the data is explicit about this, but I will also assume the student has followed some of the clues referenced in the codebook. For example, Cohen's $\kappa$ is a measure of similarity/association and is a suggested "default" for modeling dyadic foreign policy similarity using valued voting data in the United Nations General Assembly. You can read more about it on the [`add_fpsim()`](http://svmiller.com/peacesciencer/reference/add_fpsim.html) documentation on the website for `{peacesciencer}`.

\newpage

# Appendix: My Analyses of Economic Aid by the Carter Administration in 1979

dd

```{r, echo=F}
library(modelsummary)
library(sandwich)
library(tinytable)
set.seed(8675309)
modelsummary(list("Original Model" = M1, 
                  "With Transformations" = M3, 
                  "Robustness Corrections" = M1), 
             stars=TRUE,
             title = "An Analysis of Economic Aid Allocation by the Carter Administration in 1979",
             coef_map = c(
               "clphy" = "Physical Violence Index",
               "fpsusa" = "Cohen's k (U.S.)",
               "fpsrus" = "Cohen's k (USSR)",
               "mindistusa" = "Minimum Distance (U.S.)",
               "ln_mindistusa" = "Minimum Distance (U.S.)",
               "usaimp" = "Value of Imports to U.S.",
               "ln_usaimp" = "Value of Imports to U.S.",
               "gdppc" = "GDP per Capita",
               "ln_gdppc" = "GDP per Capita",
               "milexpc" = "Milit. Exp. per Capita",
               "ln_milexpc" = "Milit. Exp. per Capita",
               "cinc" = "CINC",
               "(Intercept)" = "Intercept"),
             gof_map = c("nobs", "r.squared", "adj.r.squared"),
             vcov = list(vcovHC(M1,type='const'),
                         vcovHC(M3,type='const'),
                         vcovBS(M1))) %>%
  style_tt(i = 0, j=1:4,
           bold = TRUE) %>%
  theme_tt("resize", width = .9) %>%
  theme_tt("placement", latex_float = "H") 
```